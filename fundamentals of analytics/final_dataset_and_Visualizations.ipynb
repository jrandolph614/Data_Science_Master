{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d55def-bc2d-43ae-a1ec-110b8140a72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# requirements\n",
    "import string\n",
    "import re\n",
    "import pandas as pd\n",
    "import textblob\n",
    "import nltk.corpus\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.layers import Dense, Conv1D, Flatten, Dropout, Activation\n",
    "#Functions\n",
    "def remove_punc(row):\n",
    "punc = string.punctuation\n",
    "temp = ''\n",
    "for word in row['text']:\n",
    "if word not in punc:\n",
    "temp+=word\n",
    "row['text'] = temp\n",
    "return row['text']\n",
    "def splitter_remover(row):\n",
    "temp = row['text']\n",
    "temp = temp.split()\n",
    "temp = [words for words in temp if len(words)>1]\n",
    "row['text'] = temp\n",
    "return row['text']\n",
    "def stopWords(row):\n",
    "temp= [words for words in row['text'] if words not in stop]\n",
    "row['text'] = temp\n",
    "return row['text']\n",
    "def word_stem(row):\n",
    "temp = [PorterStemmer().stem(i) for i in row['text']]\n",
    "row['text'] = temp\n",
    "return row['text']\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "def word_lem(row):\n",
    "temp = [WordNetLemmatizer().lemmatize(i) for i in row['text']]\n",
    "row['text'] = temp\n",
    "return row['text']\n",
    "def removeInt(row):\n",
    "temp = [word for word in row['text'] if not isinstance(word,int)]\n",
    "row['text'] = temp\n",
    "return row['text']\n",
    "def strcon(row):\n",
    "temp = [str(item) for item in row['text']]\n",
    "row['text'] = temp\n",
    "return row['text']\n",
    "def cleanup(row):\n",
    "temp=''\n",
    "for i in row['text']:\n",
    "temp+=i+\" \"\n",
    "row['text'] = temp\n",
    "return row['text']\n",
    "def tester(y_pred, y_true):\n",
    "recall = sklearn.metrics.recall_score(y_true, y_pred)\n",
    "precision = sklearn.metrics.precision_score(y_true, y_pred)\n",
    "f1 = sklearn.metrics.f1_score(y_true, y_pred)\n",
    "fbeta = sklearn.metrics.fbeta_score(y_true,y_pred, beta=0.5)\n",
    "accuracy = sklearn.metrics.accuracy_score(y_true,y_pred)\n",
    "print('Accuracy', accuracy)\n",
    "print('Recall score', recall)\n",
    "print('Precision score', precision)\n",
    "print('f1 score', f1)\n",
    "print('fbeta score', fbeta)\n",
    "return [accuracy, recall, precision, f1, fbeta]\n",
    "# import data\n",
    "data = pd.read_csv('Data/final_data.csv', index_col=0)\n",
    "ham = data[data['ham_spam']==0]\n",
    "spam = data[data['ham_spam']==1]\n",
    "test_size = [.25,.5,1,2,4]\n",
    "data = {'model_name': [], 'accuracy': [], \"recall\": [], 'precision': []\n",
    ", \"f1_score\":[],'fbeta_score': [], 'ham_number': [], 'spam_number':[],\n",
    "'true_neg':[], 'false_pos':[], 'false_neg':[], 'true_pos': []}\n",
    "df_final = pd.DataFrame(data=data)\n",
    "for q in test_size:\n",
    "ham = ham.sample(n =round(len(spam)*q), random_state=1,\n",
    "replace=True).reset_index(drop=True)\n",
    "data_cut = ham.append(spam)\n",
    "data_cut = data_cut.sample(len(data_cut),random_state=1).reset_index(drop=True)\n",
    "#data cleaning and feature engineering\n",
    "#lower text\n",
    "data_cut['text'] = data_cut['text'].str.lower()\n",
    "#extra whitespace\n",
    "data_cut['text'] = data_cut['text'].str.replace(r'\\s+',\" \")\n",
    "#next lines\n",
    "data_cut['text'] = data_cut['text'].str.replace(r'\\\\n',\" \")\n",
    "data_cut['text'] = data_cut['text'].str.replace(r'\\n',\" \")\n",
    "data_cut['text'] = data_cut['text'].str.replace(r'\\r',\" \")\n",
    "#subject\n",
    "data_cut['text'] = data_cut['text'].str.replace('subject',\"\")\n",
    "#names\n",
    "data_cut['text'] = data_cut['text'].str.replace('jeremy randolph',\"name\")\n",
    "data_cut['text'] = data_cut['text'].str.replace('jeremy',\"name\")\n",
    "#phone number\n",
    "data_cut['text'] =\n",
    "data_cut['text'].str.replace(r'^\\(?[\\d]{3}\\)?[\\s-]?[\\d]{3}[\\s-]?[\\d]{4}$',\"contact number\")\n",
    "#email addresses\n",
    "data_cut['text'] = data_cut['text'].str.replace(r'^.+@[^\\.].*\\.[a-z]{2,}$',\"email\")\n",
    "#currency\n",
    "data_cut['text'] = data_cut['text'].str.replace(r'Â£|\\$',\"money\")\n",
    "#hyperlinks\n",
    "data_cut['text'] =\n",
    "data_cut['text'].str.replace(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*',\"links\")\n",
    "#removing numbers\n",
    "data_cut['text'] = data_cut['text'].str.replace(r'\\d+(\\.\\d+)?',\" \")\n",
    "#remove special chartacters\n",
    "data_cut['text'] = data_cut['text'].str.replace(r'[^a-zA-Z0-9]+',\" \")\n",
    "#remove punctuation\n",
    "data_cut['text'] = data_cut.apply(remove_punc,axis=1)\n",
    "#split and remove single letter words\n",
    "data_cut['text'] = data_cut.apply(splitter_remover,axis=1)\n",
    "#stop words\n",
    "data_cut['text'] = data_cut.apply(stopWords,axis=1)\n",
    "#stemming to root words\n",
    "#data_cut['text'] = data_cut.apply(word_stem,axis=1)\n",
    "#lemmatization\n",
    "data_cut['text'] = data_cut.apply(word_lem,axis=1)\n",
    "#remove int\n",
    "data_cut['text'] = data_cut.apply(removeInt,axis=1)\n",
    "#make str\n",
    "data_cut['text'] = data_cut.apply(strcon,axis=1)\n",
    "#list to str\n",
    "data_cut['text'] = data_cut.apply(cleanup,axis=1)\n",
    "#train test split\n",
    "x_train,x_test,y_train,y_test = train_test_split(data_cut['text'],data_cut['ham_spam'],\n",
    "random_state=1, test_size=0.1)\n",
    "#y_train = np.asarray(y_train)\n",
    "#y_test = np.asarray(y_test)\n",
    "#tfidf\n",
    "vector = TfidfVectorizer(sublinear_tf=True, max_df=0.5, stop_words='english')\n",
    "features_train = vector.fit_transform(x_train)\n",
    "features_test = vector.transform(x_test)\n",
    "#Naive Bayes\n",
    "nb = MultinomialNB()\n",
    "nb.fit(features_train, y_train)\n",
    "#score_train = nb.score(features_train, y_train)\n",
    "#score_test = nb.score(features_test, y_test)\n",
    "y_pred = nb.predict(features_test)\n",
    "#matrix = confusion_matrix(y_test,y_pred)\n",
    "#matrix\n",
    "'''import seaborn as sns\n",
    "from cf_matrix import make_confusion_matrix\n",
    "labels =['True Neg','False Pos','False Neg','True Pos']\n",
    "#ax =sns.heatmap(matrix, annot=True, fmt='d', group_names=labels)\n",
    "make_confusion_matrix(matrix, group_names=labels, figsize=(8,6))\n",
    "'''\n",
    "#svm\n",
    "kernal = ['linear','poly','rbf','sigmoid']\n",
    "for k in kernal:\n",
    "clf = SVC(kernel=k )\n",
    "clf.fit(features_train,y_train)\n",
    "y_pred =clf.predict(features_test)\n",
    "#print('Kernal: ',k)\n",
    "#tester(y_pred,y_test)\n",
    "#neural net\n",
    "model = keras.models.Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(features_test.shape[1],)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "#from keras.layers import Sequential\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#print(model.metrics_names)\n",
    "batch_size = 64\n",
    "epochs = 3\n",
    "history = model.fit(features_train, np.array(y_train), batch_size=batch_size,\n",
    "epochs=epochs, verbose=1 )\n",
    "score = model.evaluate(features_test, np.array(y_test), batch_size=batch_size,\n",
    "verbose=1)\n",
    "#print('Test loss:', score[0])\n",
    "#print('Test accuracy:', score[1])\n",
    "kernel = ['linear','poly','rbf','sigmoid']\n",
    "models = [nb, clf,model]\n",
    "models = {'Naive Bayes':nb, \"Svm\":clf, \"Neural Network\": model}\n",
    "data = {'model_name': [], 'accuracy': [], \"recall\": [], 'precision': []\n",
    ", \"f1_score\":[],'fbeta_score': [], 'ham_number': [], 'spam_number':[],\n",
    "'true_neg':[], 'false_pos':[], 'false_neg':[], 'true_pos': []}\n",
    "for names, model in models.items():\n",
    "if names != 'Svm':\n",
    "y_pred = model.predict(features_test)\n",
    "if names == 'Neural Network':\n",
    "y_final = []\n",
    "for i in y_pred:\n",
    "y_final.append(round(i[0]))\n",
    "res = tester(y_final,y_test)\n",
    "matrix = confusion_matrix(y_true=y_test,y_pred=y_final)\n",
    "data['true_neg'].append(matrix[0][0])\n",
    "data['false_pos'].append(matrix[0][1])\n",
    "data['false_neg'].append(matrix[1][0])\n",
    "data['true_pos'].append(matrix[1][1])\n",
    "data['ham_number'].append(len(ham))\n",
    "data['spam_number'].append(len(spam))\n",
    "else:\n",
    "res = tester(y_pred,y_test)\n",
    "matrix = confusion_matrix(y_true=y_test,y_pred=y_pred)\n",
    "data['true_neg'].append(matrix[0][0])\n",
    "data['false_pos'].append(matrix[0][1])\n",
    "data['false_neg'].append(matrix[1][0])\n",
    "data['true_pos'].append(matrix[1][1])\n",
    "data['ham_number'].append(len(ham))\n",
    "data['spam_number'].append(len(spam))\n",
    "count=0\n",
    "for key, point in data.items():\n",
    "if count <6:\n",
    "if key == 'model_name':\n",
    "data[key].append(names)\n",
    "else:\n",
    "try:\n",
    "data[key].append(res[count])\n",
    "count+=1\n",
    "except:\n",
    "pass\n",
    "else:\n",
    "for i in kernel:\n",
    "clf = SVC(kernel=i)\n",
    "clf.fit(features_train,y_train)\n",
    "y_pred =clf.predict(features_test)\n",
    "res = tester(y_pred,y_test)\n",
    "matrix = confusion_matrix(y_true=y_test,y_pred=y_pred)\n",
    "data['true_neg'].append(matrix[0][0])\n",
    "data['false_pos'].append(matrix[0][1])\n",
    "data['false_neg'].append(matrix[1][0])\n",
    "data['true_pos'].append(matrix[1][1])\n",
    "data['ham_number'].append(len(ham))\n",
    "data['spam_number'].append(len(spam))\n",
    "count = 0\n",
    "for key, point in data.items():\n",
    "if count <6:\n",
    "if key == 'model_name':\n",
    "data[key].append('Svm_'+i)\n",
    "else:\n",
    "try:\n",
    "data[key].append(res[count])\n",
    "count+=1\n",
    "except:\n",
    "pass\n",
    "df = pd.DataFrame(data=data)\n",
    "df_final = df_final.append(df)\n",
    "print(q)\n",
    "df_final['total_average'] = (df_final.iloc[:,1:6].sum(axis=1))/5\n",
    "df_final['ham_spam_ratio'] = round(df_final['ham_number']/df_final['spam_number'] ,2)\n",
    "df_final.to_csv('final_stats.csv')\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "df_model = df_final\n",
    "fig = px.bar(data_frame=df_model, x='ham_spam_ratio', y='total_average',\n",
    "color='model_name',color_discrete_sequence=px.colors.qualitative.D3, title ='Overall\n",
    "Model Performance by Ratio')\n",
    "'''fig.update_traces(marker=dict(size=11, opacity=.8,line=dict(width=2,\n",
    "color='DarkSlateGrey')))'''\n",
    "fig.update_layout(barmode='group')\n",
    "fig.show()\n",
    "df_model = df_final.groupby(by=['ham_spam_ratio'],\n",
    "as_index=False)['total_average'].mean()\n",
    "df_model.sort_values(by='ham_spam_ratio',ascending=True,inplace=True)\n",
    "df_model['ham_spam_ratio'] =df_model['ham_spam_ratio'].astype(str)\n",
    "#df_model\n",
    "fig = px.bar( data_frame=df_model, x='total_average', y='ham_spam_ratio',\n",
    "color='ham_spam_ratio',color_discrete_sequence=px.colors.qualitative.D3, title='Ham\n",
    "Spam Ratio Total Average Performance')\n",
    "#fig.update_traces(marker=dict(size=11, opacity=.8,line=dict(width=2,\n",
    "#color='DarkSlateGrey')))\n",
    "fig.show()\n",
    "#confusion\n",
    "import numpy as np\n",
    "data = np.asarray([[410,0],[3,211]])\n",
    "from cf_matrix import make_confusion_matrix\n",
    "#make_confusion_matrix(data)\n",
    "labels =['True Neg','False Pos','False Neg','True Pos']\n",
    "#ax =sns.heatmap(matrix, annot=True, fmt='d', group_names=labels)\n",
    "make_confusion_matrix(data, group_names=labels, figsize=(8,6),title='SVM RBF\n",
    "Kernel: Ham Spam Ratio 2:1')\n",
    "#best overall performance\n",
    "df_model = df_final.groupby(by=['model_name'], as_index=False)\n",
    "df_model = df_model.apply(lambda x: x.sort_values('total_average',ascending=False))\n",
    "df_model = df_model.groupby('model_name').head(1)\n",
    "df_model.reset_index(drop=True, inplace=True)\n",
    "df_model.to_csv('best_model_performance.csv')\n",
    "#best precison\n",
    "df_model = df_final.groupby(by=['model_name'], as_index=False)\n",
    "df_model = df_model.apply(lambda x: x.sort_values('precision',ascending=False))\n",
    "df_model = df_model.groupby('model_name').head(1)\n",
    "df_model.reset_index(drop=True, inplace=True)\n",
    "df_model.to_csv('best_model_precision.csv')\n",
    "#best fbeta\n",
    "df_model = df_final.groupby(by=['model_name'], as_index=False)\n",
    "df_model = df_model.apply(lambda x: x.sort_values('precision',ascending=False))\n",
    "df_model = df_model.groupby('model_name').head(1)\n",
    "df_model.reset_index(drop=True, inplace=True)\n",
    "df_model.to_csv('best_model_fbeta.csv')\n",
    "df_model = df_final\n",
    "df_model['ham_spam_ratio'] =df_model['ham_spam_ratio'].astype(str)\n",
    "fig = px.bar(df_model, x='model_name', y='fbeta_score',\n",
    "facet_col='ham_spam_ratio',facet_col_wrap=10,title='Fbeta Analysis for Each Model')\n",
    "fig.show()\n",
    "df_model = df_final\n",
    "df_model['ham_spam_ratio'] =df_model['ham_spam_ratio'].astype(str)\n",
    "fig = px.bar(df_model, x='model_name', y='precision',\n",
    "facet_col='ham_spam_ratio',facet_col_wrap=10,title='Precision Analysis for Each\n",
    "Model')\n",
    "fig.show()\n",
    "df_model = df_final\n",
    "df_model['ham_spam_ratio'] =df_model['ham_spam_ratio'].astype(str)\n",
    "fig = px.bar(df_model, x='model_name', y='total_average',\n",
    "facet_col='ham_spam_ratio',facet_col_wrap=10,title='Total Average Analysis for Each\n",
    "Model')\n",
    "fig.show()\n",
    "df_model = df_final\n",
    "df_model['ham_spam_ratio'] =df_model['ham_spam_ratio'].astype(str)\n",
    "fig = px.bar(df_model, x='model_name', y='accuracy',\n",
    "facet_col='ham_spam_ratio',facet_col_wrap=10,title='Accuracy Analysis for Each\n",
    "Model')\n",
    "fig.show()\n",
    "df_model = df_final\n",
    "df_model['ham_spam_ratio'] =df_model['ham_spam_ratio'].astype(str)\n",
    "fig = px.bar(df_model, x='model_name', y='recall',\n",
    "facet_col='ham_spam_ratio',facet_col_wrap=10,title='Recall Analysis for Each Model')\n",
    "fig.show()\n",
    "df_model = df_final\n",
    "df_model['ham_spam_ratio'] =df_model['ham_spam_ratio'].astype(str)\n",
    "fig = px.bar(df_model, x='model_name', y='f1_score',\n",
    "facet_col='ham_spam_ratio',facet_col_wrap=10,title='F1 Analysis for Each Model')\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
